{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Projeto ETL - Dados de Absente\u00edsmo","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do projeto ETL para processamento de dados de absente\u00edsmo.</p>"},{"location":"#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Este projeto implementa um pipeline ETL (Extract, Transform, Load) para processar dados de absente\u00edsmo de funcion\u00e1rios armazenados em arquivos Excel.</p>"},{"location":"#funcionalidades","title":"Funcionalidades","text":"<ul> <li>Extra\u00e7\u00e3o: L\u00ea m\u00faltiplos arquivos Excel da pasta <code>data/raw/</code></li> <li>Transforma\u00e7\u00e3o: Combina todos os DataFrames em um \u00fanico dataset</li> <li>Carregamento: Salva o resultado em arquivo Excel na pasta <code>data/processed/</code></li> <li>Testes: Suite de testes automatizados com pytest</li> <li>Qualidade: Verifica\u00e7\u00e3o de c\u00f3digo com blue, isort e pydocstyle</li> </ul>"},{"location":"#estrutura-do-projeto","title":"Estrutura do Projeto","text":"<pre><code>estrutura-de-projeto/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/          # Dados brutos (arquivos Excel)\n\u2502   \u2514\u2500\u2500 processed/    # Dados processados\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 etl/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 etl_absenteeism.py  # Classe principal ETL\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_etl.py   # Testes automatizados\n\u251c\u2500\u2500 docs/             # Documenta\u00e7\u00e3o\n\u251c\u2500\u2500 main.py           # Ponto de entrada\n\u2514\u2500\u2500 pyproject.toml    # Configura\u00e7\u00f5es do projeto\n</code></pre>"},{"location":"#como-usar","title":"Como Usar","text":""},{"location":"#instalacao","title":"Instala\u00e7\u00e3o","text":"<pre><code>uv sync\n</code></pre>"},{"location":"#executar-etl","title":"Executar ETL","text":"<pre><code>uv run task run\n</code></pre>"},{"location":"#rodar-testes","title":"Rodar Testes","text":"<pre><code>uv run pytest\n</code></pre>"},{"location":"#verificar-qualidade-do-codigo","title":"Verificar Qualidade do C\u00f3digo","text":"<pre><code>uv run task format\n</code></pre>"},{"location":"#servir-documentacao","title":"Servir Documenta\u00e7\u00e3o","text":"<pre><code>uv run task docs-serve\n</code></pre>"},{"location":"#dados","title":"Dados","text":"<p>O projeto processa dados de absente\u00edsmo com as seguintes colunas:</p> <ul> <li>Colaborador_id: ID \u00fanico do funcion\u00e1rio</li> <li>Colaborador_nome: Nome do funcion\u00e1rio</li> <li>Departamento: Departamento do funcion\u00e1rio</li> <li>Motivo_da_aus\u00eancia: Raz\u00e3o da aus\u00eancia</li> <li>Horas_de_aus\u00eancia: Quantidade de horas ausentes</li> <li>Data_da_aus\u00eancia: Data da aus\u00eancia</li> <li>Sal\u00e1rio: Sal\u00e1rio do funcion\u00e1rio</li> </ul>"},{"location":"#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>O projeto usa:</p> <ul> <li>Python 3.11+</li> <li>pandas para manipula\u00e7\u00e3o de dados</li> <li>openpyxl para leitura de arquivos Excel</li> <li>pytest para testes</li> <li>blue para formata\u00e7\u00e3o de c\u00f3digo</li> <li>isort para organiza\u00e7\u00e3o de imports</li> <li>pydocstyle para verifica\u00e7\u00e3o de docstrings</li> <li>mkdocs para documenta\u00e7\u00e3o</li> </ul>"},{"location":"tests/","title":"Testes","text":"<p>Este projeto utiliza pytest para garantir a qualidade e confiabilidade do c\u00f3digo. Os testes cobrem as principais funcionalidades do pipeline ETL.</p>"},{"location":"tests/#estrategia-de-testes","title":"Estrat\u00e9gia de Testes","text":""},{"location":"tests/#tipos-de-teste","title":"Tipos de Teste","text":"<ol> <li>Testes Unit\u00e1rios: Testam m\u00e9todos individuais da classe <code>EtlAbsenteeism</code></li> <li>Testes de Integra\u00e7\u00e3o: Verificam o funcionamento completo do pipeline</li> <li>Testes de Valida\u00e7\u00e3o: Garantem que os dados s\u00e3o processados corretamente</li> </ol>"},{"location":"tests/#testes-implementados","title":"Testes Implementados","text":""},{"location":"tests/#test_extract_data","title":"<code>test_extract_data()</code>","text":"<p>Objetivo: Verificar se a extra\u00e7\u00e3o de dados funciona corretamente.</p> <p>Valida\u00e7\u00f5es: - Retorna uma lista de DataFrames - Encontra arquivos na pasta especificada - Cada item da lista \u00e9 um DataFrame v\u00e1lido</p> <pre><code>def test_extract_data():\n    \"\"\"Testa se consegue extrair todos os dados\"\"\"\n    etl = EtlData(\"data/raw\")\n    dataframes = etl.extract_data(\"*.xlsx\")\n\n    assert isinstance(dataframes, list)\n    assert len(dataframes) &gt; 0\n    for df in dataframes:\n        assert isinstance(df, pd.DataFrame)\n</code></pre>"},{"location":"tests/#test_transform_data_join","title":"<code>test_transform_data_join()</code>","text":"<p>Objetivo: Testar a combina\u00e7\u00e3o de m\u00faltiplos DataFrames.</p> <p>Valida\u00e7\u00f5es: - Combina DataFrames corretamente - Preserva todas as linhas e colunas - Mant\u00e9m a ordem dos dados</p> <pre><code>def test_transform_data_join():\n    \"\"\"Testa se junta os DataFrames corretamente\"\"\"\n    # Cria DataFrames de teste\n    df1 = pd.DataFrame({...})\n    df2 = pd.DataFrame({...})\n\n    # Testa a jun\u00e7\u00e3o\n    result = etl.tranform_data([df1, df2])\n\n    assert isinstance(result, pd.DataFrame)\n    assert len(result) == 4  # 2 + 2 = 4 linhas\n</code></pre>"},{"location":"tests/#test_transform_single_dataframe","title":"<code>test_transform_single_dataframe()</code>","text":"<p>Objetivo: Verificar comportamento com apenas um DataFrame.</p> <p>Valida\u00e7\u00f5es: - Processa corretamente um \u00fanico DataFrame - Mant\u00e9m estrutura original - N\u00e3o introduz erros desnecess\u00e1rios</p>"},{"location":"tests/#test_integration_full_pipeline","title":"<code>test_integration_full_pipeline()</code>","text":"<p>Objetivo: Testar o pipeline completo end-to-end.</p> <p>Valida\u00e7\u00f5es: - Extra\u00e7\u00e3o \u2192 Transforma\u00e7\u00e3o funciona - Dados s\u00e3o processados corretamente - Pipeline completo \u00e9 executado sem erros</p>"},{"location":"tests/#executando-os-testes","title":"Executando os Testes","text":""},{"location":"tests/#todos-os-testes","title":"Todos os Testes","text":"<pre><code>uv run pytest\n</code></pre>"},{"location":"tests/#testes-com-verbosidade","title":"Testes com Verbosidade","text":"<pre><code>uv run pytest -v\n</code></pre>"},{"location":"tests/#testes-especificos","title":"Testes Espec\u00edficos","text":"<pre><code>uv run pytest tests/test_etl.py::test_extract_data\n</code></pre>"},{"location":"tests/#com-coverage","title":"Com Coverage","text":"<pre><code>uv run pytest --cov=src\n</code></pre>"},{"location":"tests/#estrutura-dos-dados-de-teste","title":"Estrutura dos Dados de Teste","text":"<p>Os testes utilizam DataFrames simulados com a estrutura:</p> <pre><code>df_test = pd.DataFrame({\n    \"ID\": [1, 2],\n    \"Nome\": [\"Jo\u00e3o\", \"Maria\"],\n    \"Salario\": [5000, 6000]\n})\n</code></pre>"},{"location":"tests/#validacoes-de-qualidade","title":"Valida\u00e7\u00f5es de Qualidade","text":""},{"location":"tests/#assertions-principais","title":"Assertions Principais","text":"<ul> <li>Tipo de retorno: <code>isinstance(result, expected_type)</code></li> <li>Tamanho dos dados: <code>len(dataframes) &gt; 0</code></li> <li>Estrutura: <code>len(result.columns) == expected_columns</code></li> <li>Conte\u00fado: <code>result[\"column\"].tolist() == expected_values</code></li> </ul>"},{"location":"tests/#cenarios-testados","title":"Cen\u00e1rios Testados","text":"<ol> <li>Cen\u00e1rio Normal: M\u00faltiplos arquivos v\u00e1lidos</li> <li>Cen\u00e1rio Unit\u00e1rio: Apenas um arquivo</li> <li>Cen\u00e1rio Vazio: Nenhum arquivo encontrado (impl\u00edcito)</li> <li>Cen\u00e1rio de Integra\u00e7\u00e3o: Pipeline completo</li> </ol>"},{"location":"tests/#beneficios-dos-testes","title":"Benef\u00edcios dos Testes","text":"<ul> <li>Confiabilidade: Garante que o c\u00f3digo funciona como esperado</li> <li>Manutenibilidade: Detecta quebras durante mudan\u00e7as</li> <li>Documenta\u00e7\u00e3o: Serve como documenta\u00e7\u00e3o viva do comportamento</li> <li>Refatora\u00e7\u00e3o Segura: Permite mudan\u00e7as com confian\u00e7a</li> </ul>"},{"location":"tests/#metricas-de-cobertura","title":"M\u00e9tricas de Cobertura","text":"<p>Os testes cobrem: - \u2705 M\u00e9todo <code>extract_data()</code> - \u2705 M\u00e9todo <code>tranform_data()</code> - \u2705 Pipeline de integra\u00e7\u00e3o - \u26a0\ufe0f M\u00e9todo <code>load_data()</code> (pode ser adicionado)</p>"},{"location":"tests/#configuracao-de-teste","title":"Configura\u00e7\u00e3o de Teste","text":"<p>O arquivo <code>test_etl.py</code> inclui configura\u00e7\u00e3o para: - Resolu\u00e7\u00e3o de paths de m\u00f3dulos - Imports corretos do c\u00f3digo fonte - Execu\u00e7\u00e3o independente com <code>if __name__ == \"__main__\"</code></p>"},{"location":"tests/#exemplo-de-execucao","title":"Exemplo de Execu\u00e7\u00e3o","text":"<pre><code>$ uv run pytest tests/test_etl.py -v\n\n=== test session starts ===\ntests/test_etl.py::test_extract_data PASSED\ntests/test_etl.py::test_transform_data_join PASSED\ntests/test_etl.py::test_transform_single_dataframe PASSED\ntests/test_etl.py::test_integration_full_pipeline PASSED\n\n=== 4 passed in 0.15s ===\n</code></pre>"},{"location":"api/etl_absenteeism/","title":"API Reference - ETL Absenteeism","text":"<p>Esta p\u00e1gina cont\u00e9m a documenta\u00e7\u00e3o autom\u00e1tica gerada a partir das docstrings da classe <code>EtlAbsenteeism</code>.</p>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism","title":"<code>src.etl.etl_absenteeism</code>","text":"<p>M\u00f3dulo para processamento ETL de dados.</p>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism.EtlAbsenteeism","title":"<code>EtlAbsenteeism</code>","text":"<p>Classe para fazer ETL de arquivos em uma pasta espec\u00edfica.</p> Source code in <code>src/etl/etl_absenteeism.py</code> <pre><code>class EtlAbsenteeism:\n    \"\"\"Classe para fazer ETL de arquivos em uma pasta espec\u00edfica.\"\"\"\n\n    def __init__(self, data_path: str):\n        \"\"\"Inicializa o processador ETL.\n\n        Args:\n            data_path: Caminho da pasta.\n        \"\"\"\n        self.data_path = data_path\n\n    def extract_data(self, file_type: str) -&gt; List[pd.DataFrame]:\n        \"\"\"M\u00e9todo para ler os arquivos e retornar uma lista de dataframes.\n\n        Args:\n            file_type (str): tipo de arquivo.\n\n        Returns:\n            Lista de dataframes.\n        \"\"\"\n        files = glob.glob(os.path.join(self.data_path, file_type))\n\n        df_list = []\n\n        for file in files:\n            df_list.append(pd.read_excel(file))\n\n        return df_list\n\n    def tranform_data(\n        self, data_frame_list: List[pd.DataFrame]\n    ) -&gt; pd.DataFrame:\n        \"\"\"M\u00e9todo para juntar os dataframes.\n\n        Args:\n            data_frame_list: Lista de DataFrames para combinar.\n\n        Returns:\n            DataFrame unido.\n        \"\"\"\n        return pd.concat(data_frame_list)\n\n    def load_data(\n        self, data_frame: pd.DataFrame, output_path: str, file_name: str\n    ) -&gt; bool:\n        \"\"\"Recebe o dataframe e cria o arquivo xlsx final.\n\n        Args:\n            data_frame (pd.DataFrame): dataframe a ser salvo.\n            output_path: pasta de destino.\n            file_name: nome do arquivo salvo.\n\n        Returns:\n            True se sucesso, False se erro.\n        \"\"\"\n        try:\n\n            if not os.path.exists(output_path):\n                os.makedirs(output_path)\n\n            data_frame.to_excel(f'{output_path}/{file_name}.xlsx', index=False)\n            return True\n        except Exception:\n            return False\n</code></pre>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism.EtlAbsenteeism.__init__","title":"<code>__init__(data_path: str)</code>","text":"<p>Inicializa o processador ETL.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>Caminho da pasta.</p> required Source code in <code>src/etl/etl_absenteeism.py</code> <pre><code>def __init__(self, data_path: str):\n    \"\"\"Inicializa o processador ETL.\n\n    Args:\n        data_path: Caminho da pasta.\n    \"\"\"\n    self.data_path = data_path\n</code></pre>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism.EtlAbsenteeism.extract_data","title":"<code>extract_data(file_type: str) -&gt; List[pd.DataFrame]</code>","text":"<p>M\u00e9todo para ler os arquivos e retornar uma lista de dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>file_type</code> <code>str</code> <p>tipo de arquivo.</p> required <p>Returns:</p> Type Description <code>List[DataFrame]</code> <p>Lista de dataframes.</p> Source code in <code>src/etl/etl_absenteeism.py</code> <pre><code>def extract_data(self, file_type: str) -&gt; List[pd.DataFrame]:\n    \"\"\"M\u00e9todo para ler os arquivos e retornar uma lista de dataframes.\n\n    Args:\n        file_type (str): tipo de arquivo.\n\n    Returns:\n        Lista de dataframes.\n    \"\"\"\n    files = glob.glob(os.path.join(self.data_path, file_type))\n\n    df_list = []\n\n    for file in files:\n        df_list.append(pd.read_excel(file))\n\n    return df_list\n</code></pre>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism.EtlAbsenteeism.load_data","title":"<code>load_data(data_frame: pd.DataFrame, output_path: str, file_name: str) -&gt; bool</code>","text":"<p>Recebe o dataframe e cria o arquivo xlsx final.</p> <p>Parameters:</p> Name Type Description Default <code>data_frame</code> <code>DataFrame</code> <p>dataframe a ser salvo.</p> required <code>output_path</code> <code>str</code> <p>pasta de destino.</p> required <code>file_name</code> <code>str</code> <p>nome do arquivo salvo.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True se sucesso, False se erro.</p> Source code in <code>src/etl/etl_absenteeism.py</code> <pre><code>def load_data(\n    self, data_frame: pd.DataFrame, output_path: str, file_name: str\n) -&gt; bool:\n    \"\"\"Recebe o dataframe e cria o arquivo xlsx final.\n\n    Args:\n        data_frame (pd.DataFrame): dataframe a ser salvo.\n        output_path: pasta de destino.\n        file_name: nome do arquivo salvo.\n\n    Returns:\n        True se sucesso, False se erro.\n    \"\"\"\n    try:\n\n        if not os.path.exists(output_path):\n            os.makedirs(output_path)\n\n        data_frame.to_excel(f'{output_path}/{file_name}.xlsx', index=False)\n        return True\n    except Exception:\n        return False\n</code></pre>"},{"location":"api/etl_absenteeism/#src.etl.etl_absenteeism.EtlAbsenteeism.tranform_data","title":"<code>tranform_data(data_frame_list: List[pd.DataFrame]) -&gt; pd.DataFrame</code>","text":"<p>M\u00e9todo para juntar os dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>data_frame_list</code> <code>List[DataFrame]</code> <p>Lista de DataFrames para combinar.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame unido.</p> Source code in <code>src/etl/etl_absenteeism.py</code> <pre><code>def tranform_data(\n    self, data_frame_list: List[pd.DataFrame]\n) -&gt; pd.DataFrame:\n    \"\"\"M\u00e9todo para juntar os dataframes.\n\n    Args:\n        data_frame_list: Lista de DataFrames para combinar.\n\n    Returns:\n        DataFrame unido.\n    \"\"\"\n    return pd.concat(data_frame_list)\n</code></pre>"},{"location":"api/main/","title":"API Reference - Main Module","text":"<p>Esta p\u00e1gina cont\u00e9m a documenta\u00e7\u00e3o autom\u00e1tica gerada a partir das docstrings do m\u00f3dulo <code>main.py</code>.</p>"},{"location":"api/main/#main","title":"<code>main</code>","text":"<p>M\u00f3dulo principal para execu\u00e7\u00e3o do pipeline ETL de dados.</p>"},{"location":"api/main/#main.main","title":"<code>main()</code>","text":"<p>Executa o pipeline ETL completo para processamento dos dados.</p> Source code in <code>main.py</code> <pre><code>def main():\n    \"\"\"Executa o pipeline ETL completo para processamento dos dados.\"\"\"\n    print('=== Iniciando  ETL ===')\n\n    file_type = 'xlsx'\n    output_path = 'data/processed'\n    input_path = 'data/raw'\n\n    try:\n        etl = EtlAbsenteeism(input_path)\n        dataframes = etl.extract_data(f'*.{file_type}')\n\n        if not dataframes:\n            print('Nenhum arquivo processados!')\n            return\n\n        print(f'{len(dataframes)} arquivos carregados...')\n\n        print('Juntando os dataframes...')\n\n        transform = etl.tranform_data(dataframes)\n\n        if transform is not None and not transform.empty:\n            print('Dataframe combinado com sucesso!')\n        else:\n            print('Erro ao juntar os dataframes')\n\n        print('Salvando na pasta processed')\n\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        filename_with_timestamp = f'absenteeism_data_{timestamp}'\n\n        load = etl.load_data(transform, output_path, filename_with_timestamp)\n\n        if load:\n            print(\n                f'Arquivo {filename_with_timestamp}.{file_type} salvo com sucesso!'\n            )\n        else:\n            print('Falha ao salvar arquivo')\n\n    except Exception as e:\n        print(f'Error: {e}')\n</code></pre>"},{"location":"modules/etl/","title":"M\u00f3dulo ETL","text":"<p>O m\u00f3dulo <code>src/etl/etl_absenteeism.py</code> cont\u00e9m a classe principal respons\u00e1vel por todo o processamento ETL dos dados de absente\u00edsmo.</p>"},{"location":"modules/etl/#arquitetura","title":"Arquitetura","text":""},{"location":"modules/etl/#classe-etlabsenteeism","title":"Classe EtlAbsenteeism","text":"<p>A classe <code>EtlAbsenteeism</code> implementa o padr\u00e3o ETL seguindo os princ\u00edpios de responsabilidade \u00fanica e encapsulamento.</p> <pre><code>class EtlAbsenteeism:\n    \"\"\"Classe para fazer ETL de arquivos em uma pasta espec\u00edfica.\"\"\"\n</code></pre>"},{"location":"modules/etl/#metodos-principais","title":"M\u00e9todos Principais","text":""},{"location":"modules/etl/#1-extract-extracao","title":"1. Extract (Extra\u00e7\u00e3o)","text":"<pre><code>def extract_data(self, file_type: str) -&gt; List[pd.DataFrame]\n</code></pre> <p>Responsabilidade: Ler todos os arquivos Excel de uma pasta e converter em DataFrames.</p> <p>Funcionalidades: - Busca arquivos por padr\u00e3o (ex: <code>*.xlsx</code>) - Carrega cada arquivo como DataFrame usando <code>pandas.read_excel()</code> - Retorna lista de DataFrames para processamento</p> <p>Exemplo: <pre><code>etl = EtlAbsenteeism(\"data/raw\")\ndataframes = etl.extract_data(\"*.xlsx\")\n</code></pre></p>"},{"location":"modules/etl/#2-transform-transformacao","title":"2. Transform (Transforma\u00e7\u00e3o)","text":"<pre><code>def tranform_data(self, data_frame_list: List[pd.DataFrame]) -&gt; pd.DataFrame\n</code></pre> <p>Responsabilidade: Combinar m\u00faltiplos DataFrames em um \u00fanico dataset.</p> <p>Funcionalidades: - Concatena DataFrames verticalmente usando <code>pandas.concat()</code> - Preserva todas as linhas e colunas - Retorna DataFrame unificado</p> <p>Exemplo: <pre><code>combined_df = etl.tranform_data(dataframes)\n</code></pre></p>"},{"location":"modules/etl/#3-load-carregamento","title":"3. Load (Carregamento)","text":"<pre><code>def load_data(self, data_frame: pd.DataFrame, output_path: str, file_name: str) -&gt; bool\n</code></pre> <p>Responsabilidade: Salvar o DataFrame processado em arquivo Excel.</p> <p>Funcionalidades: - Cria pasta de destino se n\u00e3o existir - Salva DataFrame como arquivo Excel - Retorna <code>True</code> para sucesso, <code>False</code> para erro - Implementa tratamento de exce\u00e7\u00f5es</p> <p>Exemplo: <pre><code>success = etl.load_data(df, \"data/processed\", \"resultado_20240920\")\n</code></pre></p>"},{"location":"modules/etl/#dependencias","title":"Depend\u00eancias","text":"<ul> <li>pandas: Manipula\u00e7\u00e3o e an\u00e1lise de dados</li> <li>openpyxl: Leitura e escrita de arquivos Excel</li> <li>glob: Busca de arquivos por padr\u00e3o</li> <li>os: Opera\u00e7\u00f5es do sistema operacional</li> </ul>"},{"location":"modules/etl/#fluxo-de-dados","title":"Fluxo de Dados","text":"<pre><code>graph LR\n    A[Arquivos Excel] --&gt; B[extract_data]\n    B --&gt; C[Lista de DataFrames]\n    C --&gt; D[tranform_data]\n    D --&gt; E[DataFrame \u00danico]\n    E --&gt; F[load_data]\n    F --&gt; G[Arquivo Excel Final]\n</code></pre>"},{"location":"modules/etl/#vantagens-da-arquitetura","title":"Vantagens da Arquitetura","text":"<ol> <li>Modularidade: Cada m\u00e9todo tem responsabilidade espec\u00edfica</li> <li>Reutiliza\u00e7\u00e3o: M\u00e9todos podem ser usados independentemente</li> <li>Testabilidade: Cada m\u00e9todo pode ser testado isoladamente</li> <li>Manutenibilidade: Mudan\u00e7as s\u00e3o localizadas e controladas</li> <li>Flexibilidade: F\u00e1cil extens\u00e3o para novos tipos de transforma\u00e7\u00e3o</li> </ol>"},{"location":"modules/etl/#casos-de-uso","title":"Casos de Uso","text":"<ul> <li>Consolida\u00e7\u00e3o de dados mensais: Juntar planilhas de diferentes meses</li> <li>Agrega\u00e7\u00e3o departamental: Combinar dados de v\u00e1rios departamentos</li> <li>Migra\u00e7\u00e3o de dados: Converter m\u00faltiplos arquivos em formato \u00fanico</li> <li>An\u00e1lise hist\u00f3rica: Unificar dados de diferentes per\u00edodos</li> </ul>"},{"location":"modules/etl/#validacoes-implementadas","title":"Valida\u00e7\u00f5es Implementadas","text":"<ul> <li>Verifica\u00e7\u00e3o de exist\u00eancia da pasta de destino</li> <li>Tratamento de exce\u00e7\u00f5es no salvamento</li> <li>Retorno booleano para valida\u00e7\u00e3o de sucesso</li> <li>Logs informativos sobre o processamento</li> </ul>"},{"location":"modules/main/","title":"M\u00f3dulo Main","text":"<p>O m\u00f3dulo <code>main.py</code> \u00e9 o ponto de entrada principal do pipeline ETL. Ele orquestra todo o processo de extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carregamento dos dados.</p>"},{"location":"modules/main/#responsabilidades","title":"Responsabilidades","text":"<ul> <li>Configura\u00e7\u00e3o: Define os caminhos de entrada e sa\u00edda dos dados</li> <li>Orquestra\u00e7\u00e3o: Coordena a execu\u00e7\u00e3o das etapas ETL</li> <li>Valida\u00e7\u00e3o: Verifica se cada etapa foi executada com sucesso</li> <li>Logging: Fornece feedback sobre o progresso do processamento</li> </ul>"},{"location":"modules/main/#fluxo-de-execucao","title":"Fluxo de Execu\u00e7\u00e3o","text":"<ol> <li>Inicializa\u00e7\u00e3o: Cria inst\u00e2ncia da classe <code>EtlAbsenteeism</code></li> <li>Extra\u00e7\u00e3o: Carrega arquivos Excel da pasta <code>data/raw/</code></li> <li>Valida\u00e7\u00e3o: Verifica se arquivos foram encontrados</li> <li>Transforma\u00e7\u00e3o: Combina DataFrames em um \u00fanico dataset</li> <li>Carregamento: Salva resultado com timestamp na pasta <code>data/processed/</code></li> <li>Confirma\u00e7\u00e3o: Exibe mensagens de sucesso ou erro</li> </ol>"},{"location":"modules/main/#configuracao","title":"Configura\u00e7\u00e3o","text":"<pre><code>file_type = 'xlsx'          # Tipo de arquivo a processar\noutput_path = 'data/processed'  # Pasta de sa\u00edda\ninput_path = 'data/raw'     # Pasta de entrada\n</code></pre>"},{"location":"modules/main/#exemplo-de-uso","title":"Exemplo de Uso","text":"<pre><code># Executar o pipeline ETL\nuv run python main.py\n\n# Sa\u00edda esperada:\n# === Iniciando ETL ===\n# 3 arquivos carregados...\n# Juntando os dataframes...\n# Dataframe combinado com sucesso!\n# Salvando na pasta processed\n# Arquivo absenteeism_data_20240920_143052.xlsx salvo com sucesso!\n</code></pre>"},{"location":"modules/main/#tratamento-de-erros","title":"Tratamento de Erros","text":"<p>O m\u00f3dulo implementa tratamento b\u00e1sico de erros:</p> <ul> <li>Arquivos n\u00e3o encontrados: Informa quando nenhum arquivo \u00e9 processado</li> <li>Erro na transforma\u00e7\u00e3o: Verifica se o DataFrame foi combinado corretamente</li> <li>Erro no salvamento: Valida se o arquivo foi salvo com sucesso</li> <li>Exce\u00e7\u00f5es gerais: Captura e exibe erros inesperados</li> </ul>"},{"location":"modules/main/#outputs","title":"Outputs","text":"<p>O arquivo gerado segue o padr\u00e3o: <pre><code>absenteeism_data_YYYYMMDD_HHMMSS.xlsx\n</code></pre></p> <p>Onde: - <code>YYYY</code>: Ano (4 d\u00edgitos) - <code>MM</code>: M\u00eas (2 d\u00edgitos) - <code>DD</code>: Dia (2 d\u00edgitos) - <code>HH</code>: Hora (2 d\u00edgitos) - <code>MM</code>: Minuto (2 d\u00edgitos) - <code>SS</code>: Segundo (2 d\u00edgitos)</p>"}]}